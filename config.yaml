trainer:
  accelerator: "gpu"
  devices: 1
  precision: 16
  check_val_every_n_epoch: 1
  enable_checkpointing: False
  gradient_clip_val: 1
  max_epochs: 10
  accumulate_grad_batches: 2
data:
  train_batch_size: 8
  eval_batch_size: 32
  # max_len: 512
  num_workers: 4
  fold: 0
model:
  name: "microsoft/mdeberta-v3-base"
  learning_rate: 1e-5
defaults:
  - override hydra/job_logging: none
  - override hydra/hydra_logging: none
hydra:
  output_subdir: null
  run:
    dir: .