# ЛЦТ 2024. Решение задачи "Алгоритм поиска предложенных скидок в телефонных разговорах с клиентами"
## Запуск решения

Для развертывания контейнера с обученной моделью достаточно выполнить
```
docker run -p 5000:5000 -d madxx31/lct-samolet-ner
```
Описание работы с API см. в соответствующем разделе ниже.

Для полного воспроизведения решения необходимо склонировать репозиторий и запустить скрипт main.sh. Скрипт обучит модели, сформирует файл с предсказаниями по тестовой выборке, а так же соберет и развернет docker-образ c API для взаимодействия с алгоритмом.

Файлы с весами модели есть внутри docker-образа, а также продублированы здесь: https://disk.yandex.ru/d/fM8PJ1TAwIP1Hg (файл microsoft-mdeberta-v3-base/model.safetensors.zip был дополнительно заархивирован в связи с ограничениями Яндекс-Диска)

## Описание решения

Поиск скидок в телефонных разговорах реализован с помощью классификации слов в разговоре на 4 класса: "упоминание скидки", "размер скидки (первое упоминание)", "размер скидки (продолжение)" и "прочее". Для классификации используется взвешенное предсказание двух нейросетевых моделей:
- microsoft/mdeberta-v3-base
- ai-forever/ruBert-base

Модели были дообучены на предоставленной выборке. В качестве функции потерь при дообучении использовался Dice Loss. Такая функция потерь лучше оптимизирует целевую метрику (F1), чем стандартная функция потерь для задачи классификации.

Так как в исходном виде модели работают на уровне токенов, было реализовано усреднение предсказаний на уровне токенов до уровня слов. Усреднение использовалось как на этапе обучения, так и на этапе предсказания.

Для оценки моделей использовалась кроссвалидация с разбиением на 5 фолдов, стратифицированных по тому, какие метки присутствуют в тексте. Было протестировано порядка 10 предобученных нейросетевых моделей, лучше всего себя показали две вышеуказанные. Для дополнительного улучшения качества и устойчивости было решено использовать взвешенное предсказание двух моделей с весами 0.47 и 0.53 (rubert и deberta соответственно). Дополнительное преимущество модели microsoft/mdeberta-v3-base - отсутствие ограничений на длину обрабатываемой последовательности. У rubert такое ограничение есть, поэтому для небольшого числа слов, которые не удалось классифицировать с помощью rubert, использовалось только  предсказание deberta.

Решение реализовано на python, с помощью библиотек pytorch, transformers, pytorch-lightning. 

Точность решения (F-мера на тестовой выборке/лидерборде) составила 0.87382

## Требовательность к ресурсам и быстродействие

В рамках нашего решения мы фокусировались на точности решения, так как оно имеет больший вес в оценке решений, и не оптимизировали производительность.
Реализованный вариант API при работе на 4 ядрах CPU обрабатывает один текст в среднем за 1.7 секунды (14 с половиной минут на всю тестовую выборку). Потребление памяти составляет порядка 4гб при обработке одного текста за запрос.

Обучение моделей производилось на GPU Nvidia 3090 и занимало порядка 5 минут. Предсказание по тестовому датасету на GPU занимало несколько секунд.

Производительность решения можно улучшить за счет квантизации, дистилляции, или использования более легковесных моделей.

## Структура репозитория
```
lct-2024-samolet/
├── bin/
├── data/
├── preds/
├── train_nn/
│   ├── config.yaml
│   ├── data_module.py
│   ├── model.py
│   ├── train.py
├── app.py
├── blend.py
├── Dockerfile
├── main.sh
├── README.md
```

- `/bin` - директория, куда сохраняются обученные модели
- `/data` - директория с данными
- `/preds` - директория, куда сохраняются предсказания моделей
- `train_nn/` - директория со скриптами для обучения нейросетей
    - `config.yaml` - конфигурационный файл с основными параметрами обучения
    - `data_module.py` - в этом файле реализован класс для подготовки данных для обучения нейросетей
    - `model.py` - в этом файле реализована сама модель, loss, расчет метрик
    - `train.py` - скрипт для запуска обучения нейросети
- `app.py` - скрипт, реализующий API
- `blend.py` - скрипт для взвешивания предсказаний нейросетей и формирования файла с предсказаниями по тестовой выборке
- `Dockerfile` - Dockerfile для сборки образа с API для взаимодействия с алгоритмом
- `main.sh` - скрипт для запуска всего пайплайна решения


## Описание API
API реализовано при помощи Flask. Реализован единственный endpoint /predict

### Формат запроса
- **URL**: `/predict`
- **Метод**: `POST`
- **Content-Type**: `application/json`
- **Тело запроса**:
  ```json
  {
	"texts": [
		"можем предложить вам скидку три процента"
	]
  }
  ```

### Ответ
  ```json
    [
        [
            "O",
            "O",
            "O",
            "B-discount",
            "B-value",
            "I-value"
        ]
    ]
  ```

